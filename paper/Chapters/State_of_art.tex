% Chapter Template

\chapter{Related Work} % Main chapter title

\label{Chapter 1} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 1. \emph{Related Work}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

%\section{State of the Art}

For over two decades, motion learning for complex structure has been a research focus. There has been many different approach to this problem, but it usually involves a simulated environment, where the creature can experiment with and get feedback from. The general problem is for this creature to learn by itself how to move in this environment in order to maximize a certain quantity such as its speed or distance with a certain ammount of energy. The creature can have different ways of controlling its body using actuators to control the angle of its joints, (or even simulated muscles) and eventually some sensors to get feedback from the world. The goal being to generate the control function  $\alpha_i(t, state) $ for each actuator's degree of freedom, that link time $t$ and eventually the state of the creature to a command that can be send to the actuator (an angle for a servomotor, or command to a motor, an electrical signal to a simulated muscle ...). A widely used approach so far, which makes sense from a biological perspective is to implement smart actuators that can be linked directly to a sensor and modify the command with a low-level control. One of the examples of this behaviour is the muscle elasticity, which will alter the consequence of a specific command depending on the state of the muscle. Another example is the Proportionnal-Integral-Derivative controller (PID) of a servomotor. It is then possible to build a model that behaves as an open-loop from a high level perspective, but which actually shows robustness due to this low-level control loops. 
Under this assumption, we have the function $\alpha_i(t)$ that are only depending on parameter $t$. Finding the set of these functions remains an optimization problem in an infinite dimensional space. Therefore it is useful to make another assumption, which is that these functions are periodic. This make sense when we observe the movements of animals in the nature. In fact we can even consider the paradigm of oscillation based movements in the nature and apply it to the $\alpha_i(t)$ functions and write them using Fourier decomposition. $$\alpha_i(t) = \sum_{k = 1}^N {b_{ki} * sin(kt)} + \sum_{k = 1}^N {b_{-ki} *  cos(kt)} + b_{0i} $$.
With this decomposition, we transform our infinite dimensional research space ( of functions ) to a finite one containing the $b_{ki}$ ($ -N <= k <= N $) coeffiscients. The parameter $N$ is a restriction over the harmonics and can be seen as a precision parameter that determines how near we can get from any periodic function. This space of resaerch remains big and does not reflects in its structure any of the physical interaction that can exists between two actuators (symmetry, graph structure) of the creature. Therefore, the following related works use different techniques to reduce the dimension of the space and also different learning techniques to obtain a solution. 

The first remarquable examples of modular robotics learning to evolve in a 3D simulated world is due to Karl Sims's Creature in 1994 \cite{karl}. In his work, the structure of the creature evolves at the same time as the control system. One way of reducing the search space of Fourier coeffiscient is to create a graph that generate oscillation (much like the brain of animals does). The neural network used in Karl's creature takes as input a set of values from different sensors and each node is a function such as the sum, product, a logical functions, trigonometric functions to generate the oscillations of the structure. He also uses Genetic Algorithms in order to optimize all the parameters of the control graph and the structure. Since then Genetic Algorithms have proven to be very efficient to solve large non-convex and non-differentiable optimization problems.

Other techniques using Central Pattern Generators (CPG) have been used on modular structures at EPFL \cite{marbach} \cite{sproewitz}. The CPG is a graph that relates directly to the physical structure in order to generate oscillation. So it is also a technique to reduce the dimension of Fourier coeffiscients space to simplify the problem and reflect the physical structure of the creature using coupled oscillators. \cite{marbach} used another type of optimization techniques to do online learning of a subset of the parameters and find a local minima.

More recently, the progress of computational power and the growing interest of building humanoid robots for different tasks in non-friendly environment, such as the initiative from Virginia Tech to build a disaster response robots, or the growing demand of the animation movie and video games industry led to new results. The approach of \cite{MuscleBasedBipeds} uses muscle-based actuators and optimize at the same time the routing of the muscles and the control of the muscle activation from a muskoloskeletal model. This approach showed robust locomotion for different speed, target directions and small ground variations in terrain.

